# -*- coding: utf-8 -*-
"""test model od clinical data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VOSHM3kUrv5I4fe5XHdCZcYEfld68gAe
"""

import os
import pydicom as dicom
import numpy as np
import pandas as pd
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import shutil
from tensorflow.keras import callbacks
from tensorflow.keras import models
from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D,Flatten
from tensorflow.keras.models import Model
import tensorflow as tf
from sklearn.model_selection import train_test_split
import cv2
import matplotlib.pyplot as plt
import json
import pylibjpeg 
import gdcm
from medpy.io import load

tf.compat.v1.disable_eager_execution()
model_path = "delete_40_percent_shuffled_last.h5"

########

import skimage
from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing
from skimage.measure import label,regionprops, perimeter
from skimage.filters import roberts, sobel
from skimage import measure, feature
from skimage.segmentation import clear_border
from skimage import data
from scipy import ndimage as ndi
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
# import pydicom as dicom
import scipy.misc

## preprocess images function

def convert_to_int(st):
	st = st.replace('"','')
	return(int(st))


#make folder

if("removal_dataset" in os.listdir("/home/city/mansure_mohsen")):
	shutil.rmtree("/home/city/mansure_mohsen/removal_dataset")

os.mkdir("removal_dataset")
folders = ['chest_normal']
for i in folders:
    os.mkdir("removal_dataset/{}".format(i))
    ## main dataset path
    files = os.listdir(os.path.join('/home/bahar/datasets/ct_scan/our_data_01_28_v2','chest_normal/chest_normal_dicom'))
    for j in files:
        os.mkdir("removal_dataset/{}/{}".format(i,j))


folders = ['covid']
for i in folders:
    os.mkdir("removal_dataset/{}".format(i))
    ## main dataset path
    files = os.listdir(os.path.join('/home/bahar/datasets/ct_scan/our_data_01_28_v2','chest_pathology/chest_covid_dicom'))
    for j in files:
        os.mkdir("removal_dataset/{}/{}".format(i,j))
		
		
folders = os.listdir("removal_dataset")
print("number of Base folders: {}".format(len(folders)))

for i in folders:
    print("number of folders in {}: {}".format(i,len(os.listdir(os.path.join("removal_dataset",i)))))

	
	
base_path = '/home/bahar/datasets/ct_scan/our_data_01_28_v2'
counter = 0
normal_cases = os.listdir(os.path.join("/home/bahar/datasets/ct_scan/our_data_01_28_v2", 'chest_normal/chest_normal_dicom'))
for case in normal_cases:
	file_values = {}
	files = sorted(os.listdir(os.path.join(base_path ,'chest_normal/chest_normal_dicom',case)))
	for tmp_i in files:
		if "dcm" in tmp_i:
			ds = dicom.dcmread(os.path.join(base_path,"chest_normal/chest_normal_dicom",case,tmp_i),force=True)
			keys = file_values.keys()
			if ds.get((0x20, 0x11)).repval not in keys:
				file_values[ds.get((0x20, 0x11)).repval] = []
				file_values[ds.get((0x20, 0x11)).repval].append(tmp_i)
			else:
				file_values[ds.get((0x20, 0x11)).repval].append(tmp_i)
	keys = file_values.keys()
	for ind in keys:
		files = file_values[ind]
		if len(files) > 2 :
			down_thr = round(len(files) * 0.2)
			up_thr = len(files) - down_thr
			for image in files:
				ds = dicom.dcmread(os.path.join(base_path,"chest_normal/chest_normal_dicom",case,image),force=True)
				if convert_to_int(ds.get((0x20, 0x13)).repval) > down_thr and convert_to_int(ds.get((0x20, 0x13)).repval) < up_thr:
					src = os.path.join(base_path,'chest_normal/chest_normal_dicom',case,image)
					dst = os.path.join('removal_dataset','chest_normal',case,image.replace('dcm','png') )
					image_2d, image_header = load(src)
					level = -600
					window = 1200
					max = level + window/2
					min = level - window/2
					image_2d[image_2d < min] = min
					image_2d[image_2d > max] = max
					image_2d = image_2d.astype("float32")
					maxx = image_2d.max()
					minn = image_2d.min()
					image_2d_scaled = ((image_2d - minn) / (maxx - minn)) * 255.0
					cv2.imwrite(dst, image_2d_scaled)
			
print("{} images have problem.".format(counter))




counter = 0
covid_cases = os.listdir(os.path.join("/home/bahar/datasets/ct_scan/our_data_01_28_v2", 'chest_pathology/chest_covid_dicom'))
for case in covid_cases:
	file_values = {}
	files = sorted(os.listdir(os.path.join(base_path ,'chest_pathology/chest_covid_dicom',case)))
	for tmp_i in files:
		if "dcm" in tmp_i:
			ds = dicom.dcmread(os.path.join(base_path,"chest_pathology/chest_covid_dicom",case,tmp_i),force=True)
			keys = file_values.keys()
			if ds.get((0x20, 0x11)).repval not in keys:
				file_values[ds.get((0x20, 0x11)).repval] = []
				file_values[ds.get((0x20, 0x11)).repval].append(tmp_i)
			else:
				file_values[ds.get((0x20, 0x11)).repval].append(tmp_i)
	keys = file_values.keys()

	for ind in keys:
		files = file_values[ind]
		if len(files) > 2 :
			down_thr = round(len(files) * 0.2)
			up_thr = len(files) - down_thr
			for image in files:
				ds = dicom.dcmread(os.path.join(base_path,"chest_pathology/chest_covid_dicom",case,image),force=True)
				if convert_to_int(ds.get((0x20, 0x13)).repval) > down_thr and convert_to_int(ds.get((0x20, 0x13)).repval) < up_thr:
					src = os.path.join(base_path,'chest_pathology/chest_covid_dicom',case,image)
					dst = os.path.join('removal_dataset','covid',case,image.replace('dcm','png') )
					image_2d, image_header = load(src)
					level = -600
					window = 1200
					max = level + window/2
					min = level - window/2
					image_2d[image_2d < min] = min
					image_2d[image_2d > max] = max
					image_2d = image_2d.astype("float32")
					maxx = image_2d.max()
					minn = image_2d.min()
					image_2d_scaled = ((image_2d - minn) / (maxx - minn)) * 255.0
					cv2.imwrite(dst, image_2d_scaled)
print("{} images have problem.".format(counter))


with tf.device('/device:GPU:0'):
    base_model = tf.keras.applications.DenseNet201(weights = 'imagenet', include_top = False,input_shape=(224,224,3))
    x = base_model.output
    x = Flatten()(x)
    x = Dropout(0.5)(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(1, activation = 'sigmoid')(x)
    model = Model(base_model.input,predictions)

model.compile(loss='binary_crossentropy',
                optimizer=optimizers.Adam(lr=1e-4),
                metrics=['acc'])

model.load_weights(model_path)


import collections
from tensorflow.keras.preprocessing import image

normal_classes = []

case_folders = os.listdir(os.path.join("removal_dataset","chest_normal"))
for i in case_folders:
    folder_path = os.path.join('removal_dataset','chest_normal',i)
    images = []
    for img in os.listdir(folder_path):
        img = os.path.join(folder_path, img)

        img = image.load_img(img, target_size=(224, 224))
        img = image.img_to_array(img)
        img = img/255.0
        images.append(img)
    pred = model.predict(np.array(images))
    classes = []
    for j in pred:
        if j > 0.5:
            classes.append(1)
        else:
            classes.append(0)
    counts = collections.Counter(classes)
    normal_classes.append(counts)
    print("\n_______________________________\n\n", "for person: {} model result is:".format(i))
    print(counts)
    print("\n_______________________________\n")

with open('removal_clinical_normal_classes.json', 'w') as f:
    json.dump(normal_classes, f)


covid_classes = []

case_folders = os.listdir(os.path.join("removal_dataset","covid"))
for i in case_folders:
    folder_path = os.path.join('removal_dataset','covid',i)
    images = []
    for img in os.listdir(folder_path):
        img = os.path.join(folder_path, img)

        img = image.load_img(img, target_size=(224, 224))
        img = image.img_to_array(img)
        img = img/255.0
        images.append(img)
    pred = model.predict(np.array(images))
    classes = []
    for j in pred:
        if j > 0.5:
            classes.append(1)
        else:
            classes.append(0)
    counts = collections.Counter(classes)
    covid_classes.append(counts)
    print("\n_______________________________\n\n", "for person: {} model result is:".format(i))
    print(counts)
    print("\n_______________________________\n")

with open('removal_clinical_covid_classes.json', 'w') as f:
    json.dump(covid_classes, f)



#acc = []
#for th in [21,28,34,35,36]:
#    pos = 0
#    neg = 0
#    for j in range(len(normal_classes)):
#        if(normal_classes[j]['0'] > th):
#            pos += 1
#        else:
#            neg += 1
#    for j in range(len(covid_classes)):
#        if ('0' in covid_classes[j].keys()):
#            if(covid_classes[j]['0'] > th):
#                neg += 1
#            else:
#                pos += 1
#        else:
#            pos += 1
#    acc_temp = pos/(len(covid_classes)+len(normal_classes))
#    print("for threshold {} accuracy is equal to {}".format(th , acc_temp))
#    acc.append({th: acc_temp})

#with open('accuracy.json') as data_file:
#    accuracy = json.load(data_file)

